{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXosxKoCxNVG"
      },
      "source": [
        "# MACE in Practice II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYamp68VxNVI"
      },
      "source": [
        "In this tutorial, you will learn how to improve MLIP models by using iterative training and active learning. We illustrate these training workflows on MACE, but they are broadly applicable to all MLIPs. We will also showcase the state-of-the-art [foundational models](https://matbench-discovery.materialsproject.org/) - the latest development in the field of MLIPs. These models are trained on massive training sets of [inorganic](https://doi.org/10.48550/arXiv.2401.00096) and [organic](https://doi.org/10.48550/arXiv.2312.15211) databases and show a great deal of `out-of-the-box` MD stability in an extensive variety of [applications](https://doi.org/10.48550/arXiv.2401.00096). We will discuss [fine-tunning](https://doi.org/10.48550/arXiv.2405.20217) which is an actively-researched technique to tweak these foundational models to new systems (out of training) and/or new levels of reference theory.\n",
        "This notebook was made by Ioan Magdău and Ilyes Batatia and Will Baldwin.\n",
        "\n",
        "## Learning Objectives for today:\n",
        "\n",
        "1. **Iterative Training: improving stability and accuracy**\n",
        "2. **Active learning: committee models**\n",
        "3. **Foundational models and fine-tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2k2lPB-Eyku",
        "outputId": "a7778a87-caf5-4b15-d1dc-d7f145a14b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tutorials'...\n",
            "remote: Enumerating objects: 350, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 350 (delta 58), reused 93 (delta 35), pack-reused 230 (from 1)\u001b[K\n",
            "Receiving objects: 100% (350/350), 34.19 MiB | 8.01 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "Updating files: 100% (71/71), done.\n",
            "Collecting mace-torch\n",
            "  Downloading mace_torch-0.3.12-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting xtb\n",
            "  Downloading xtb-22.1-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting nglview\n",
            "  Downloading nglview-3.1.4.tar.gz (21.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting x3dase\n",
            "  Downloading x3dase-1.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.11/dist-packages (from mace-torch) (2.6.0+cu124)\n",
            "Collecting e3nn==0.4.4 (from mace-torch)\n",
            "  Downloading e3nn-0.4.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mace-torch) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.4.0)\n",
            "Collecting ase (from mace-torch)\n",
            "  Downloading ase-3.24.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting torch-ema (from mace-torch)\n",
            "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.15.1)\n",
            "Collecting matscipy (from mace-torch)\n",
            "  Downloading matscipy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.13.0)\n",
            "Collecting torchmetrics (from mace-torch)\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-hostlist (from mace-torch)\n",
            "  Downloading python-hostlist-2.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting configargparse (from mace-torch)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.1.44)\n",
            "Requirement already satisfied: pyYAML in /usr/local/lib/python3.11/dist-packages (from mace-torch) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mace-torch) (4.67.1)\n",
            "Collecting lmdb (from mace-torch)\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.10.15)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mace-torch) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mace-torch) (2.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from e3nn==0.4.4->mace-torch) (1.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from e3nn==0.4.4->mace-torch) (1.14.1)\n",
            "Collecting opt-einsum-fx>=0.1.4 (from e3nn==0.4.4->mace-torch)\n",
            "  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from xtb) (1.17.1)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting notebook>=7 (from nglview)\n",
            "  Downloading notebook-7.3.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jupyterlab>=3 (from nglview)\n",
            "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets in /usr/local/lib/python3.11/dist-packages (from nglview) (3.0.13)\n",
            "Collecting comm>=0.1.3 (from ipywidgets)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=3->nglview)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=3->nglview)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=3->nglview)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=3->nglview)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (24.2)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=3->nglview) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.12->mace-torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12->mace-torch) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->e3nn==0.4.4->mace-torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mace-torch) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->xtb) (2.22)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython->mace-torch) (4.0.12)\n",
            "Collecting numpy (from mace-torch)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mace-torch) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mace-torch) (2025.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->mace-torch) (0.2.13)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->mace-torch)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython->mace-torch) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=3->nglview) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (24.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab>=3->nglview) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=3->nglview)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=3->nglview) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.32.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mace-torch) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=3->nglview) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.4.0)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (24.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.6)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading mace_torch-0.3.12-py3-none-any.whl (185 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.1/185.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading e3nn-0.4.4-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.7/387.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xtb-22.1-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading x3dase-1.1.4-py3-none-any.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.4/849.4 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading notebook-7.3.3-py3-none-any.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ase-3.24.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matscipy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (448 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.8/448.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
            "Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: nglview, python-hostlist\n",
            "  Building wheel for nglview (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nglview: filename=nglview-3.1.4-py3-none-any.whl size=6370867 sha256=6108570175478a7d243155075754b40d68d1c663184c8e8bc3ed7660ecd80f01\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/79/44/9ddf94f419d3394628da6d15a9bc78624de891c58c181c9cb3\n",
            "  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-hostlist: filename=python_hostlist-2.2.1-py3-none-any.whl size=39603 sha256=961c35687693cde27da41e80f7da8fde05b6af279fffaacbc4fc51a197d17889\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/d3/7c/23728e2c3ff6d2fcc1c8b8bb7a101fa205b2f7cd37431a938b\n",
            "Successfully built nglview python-hostlist\n",
            "Installing collected packages: python-hostlist, lmdb, widgetsnbextension, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, json5, jedi, fqdn, configargparse, comm, async-lru, xtb, rdkit, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, ipywidgets, ase, x3dase, torchmetrics, torch-ema, opt-einsum-fx, matscipy, jupyter-events, e3nn, mace-torch, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, nglview\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.7\n",
            "    Uninstalling notebook-6.5.7:\n",
            "      Successfully uninstalled notebook-6.5.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 7.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 ase-3.24.0 async-lru-2.0.5 comm-0.2.2 configargparse-1.7 e3nn-0.4.4 fqdn-1.5.1 ipywidgets-8.1.5 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 lightning-utilities-0.14.2 lmdb-1.6.2 mace-torch-0.3.12 matscipy-1.1.1 nglview-3.1.4 notebook-7.3.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opt-einsum-fx-0.1.4 overrides-7.7.0 python-hostlist-2.2.1 python-json-logger-3.3.0 rdkit-2024.9.6 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 torch-ema-0.3 torchmetrics-1.7.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 widgetsnbextension-4.0.13 x3dase-1.1.4 xtb-22.1\n",
            "Collecting git+https://github.com/imagdau/aseMolec@main\n",
            "  Cloning https://github.com/imagdau/aseMolec (to revision main) to /tmp/pip-req-build-rcd4m5mf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/imagdau/aseMolec /tmp/pip-req-build-rcd4m5mf\n",
            "  Resolved https://github.com/imagdau/aseMolec to commit 2633a672eb235c49a5c7d7161f76f52f4e218e99\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: aseMolec\n",
            "  Building wheel for aseMolec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aseMolec: filename=aseMolec-1.0.0-py3-none-any.whl size=22903 sha256=a5dd38dd16d6e602c88badfb576241d67b9710e4c8f458c639957816a7d9efc2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0y01irz0/wheels/ca/6f/01/da5e58aa073ca05b020188d712a41f42460a3adbc3e8135afe\n",
            "Successfully built aseMolec\n",
            "Installing collected packages: aseMolec\n",
            "Successfully installed aseMolec-1.0.0\n",
            "Collecting numpy==2.0\n",
            "  Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "matscipy 1.1.1 requires numpy<2.0.0,>=1.16.0, but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.0\n",
            "/content/Tutorials\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/imagdau/Tutorials.git\n",
        "!pip install mace-torch xtb nglview ipywidgets rdkit x3dase\n",
        "!pip install git+https://github.com/imagdau/aseMolec@main\n",
        "!pip install -U numpy==2.0\n",
        "%cd Tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAoZccQxNVJ"
      },
      "source": [
        "## 1. Iterative Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ieIGRPOxNVK"
      },
      "source": [
        "### 1.1 MD with a smaller MACE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTK__Hd8xNVK"
      },
      "source": [
        "The model we trained in our previous tutorial was already stable in MD and quite accurate with little training. This is both because MACE models are smooth and very accurate but also because the task of simulating a single molecule for a few picoseconds is not all that difficult. In general, in real research applications, achieving MD stability and accuracy is not always straightforward from the get-go. Models can be improved through iterative training and active learning which expands the training data to fix errors on the model's potential energy surface.\n",
        "\n",
        "**To illustrate these concepts in practice, let's first train a less accurate MACE by reducing a lot the model size and amount of training data: we will make a model with just 20 training configurations. Note that a larger model would probably work out of the box for this example.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FRg6XJ0D2yG"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "db = read('data/solvent_xtb.xyz', ':')\n",
        "write('data/solvent_xtb_train_50.xyz', db[:53]) #first 50 configs plus the 3 E0s, we'll use only 20 of them for training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VleNMLWZD2yH"
      },
      "source": [
        "Let's make an input config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek3iJ6rFD2yH",
        "outputId": "138ddcc9-7a15-45ce-fe2a-ca272d612725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config/config-03.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config/config-03.yml\n",
        "\n",
        "model: \"MACE\"\n",
        "num_channels: 32\n",
        "max_L: 0\n",
        "r_max: 4.0\n",
        "name: \"mace02_com1\"\n",
        "model_dir: \"MACE_models\"\n",
        "log_dir: \"MACE_models\"\n",
        "checkpoints_dir: \"MACE_models\"\n",
        "results_dir: \"MACE_models\"\n",
        "train_file: \"data/solvent_xtb_train_20.xyz\"\n",
        "valid_file: \"data/solvent_xtb_train_50.xyz\"\n",
        "test_file: \"data/solvent_xtb_test.xyz\"\n",
        "energy_key: \"energy_xtb\"\n",
        "forces_key: \"forces_xtb\"\n",
        "device: cuda\n",
        "batch_size: 5\n",
        "max_num_epochs: 300\n",
        "swa: True\n",
        "seed: 123\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiAR1bg1D2yH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4d18b1-2fae-4b62-b1a1-597b434a1f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from mace.cli.run_train import main as mace_run_train_main\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "def train_mace(config_file_path):\n",
        "    logging.getLogger().handlers.clear()\n",
        "    sys.argv = [\"program\", \"--config\", config_file_path]\n",
        "    mace_run_train_main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl9JEPvuD2yI",
        "outputId": "166104df-10db-47a6-e970-ea361ae55868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-25 11:23:53.490 INFO: ===========VERIFYING SETTINGS===========\n",
            "2025-03-25 11:23:53.492 INFO: MACE version: 0.3.12\n",
            "2025-03-25 11:23:53.567 INFO: CUDA version: 12.4, CUDA device: 0\n",
            "2025-03-25 11:23:53.758 INFO: ===========LOADING INPUT DATA===========\n",
            "2025-03-25 11:23:53.759 INFO: Using heads: ['default']\n",
            "2025-03-25 11:23:53.761 INFO: =============    Processing head default     ===========\n",
            "2025-03-25 11:23:53.786 INFO: Using isolated atom energies from training file\n",
            "2025-03-25 11:23:53.791 INFO: Training file 1/1 [18 configs, 18 energy, 18 forces, 18 stresses] loaded from 'data/solvent_xtb_train_20.xyz'\n",
            "2025-03-25 11:23:53.792 INFO: Total training set [18 configs, 18 energy, 18 forces, 18 stresses]\n",
            "2025-03-25 11:23:53.824 INFO: Validation file 1/1 [53 configs, 53 energy, 53 forces, 53 stresses] loaded from 'data/solvent_xtb_train_50.xyz'\n",
            "2025-03-25 11:23:53.825 INFO: Total validation set [53 configs, 53 energy, 53 forces, 53 stresses]\n",
            "2025-03-25 11:23:54.158 INFO: Test file 1/1 [1000 configs, 1000 energy, 1000 forces, 1000 stresses] loaded from 'data/solvent_xtb_test.xyz'\n",
            "2025-03-25 11:23:54.159 INFO: Total test set (1000 configs):\n",
            "2025-03-25 11:23:54.162 INFO: Default_default: 1000 configs, 1000 energy, 1000 forces, 1000 stresses\n",
            "2025-03-25 11:23:54.164 INFO: Total number of configurations: train=18, valid=53, tests=[Default_default: 1000],\n",
            "2025-03-25 11:23:54.166 INFO: Atomic Numbers used: [np.int64(1), np.int64(6), np.int64(8)]\n",
            "2025-03-25 11:23:54.167 INFO: Atomic Energies used (z: eV) for head default: {1: -10.707211383396714, 6: -48.847445262804705, 8: -102.57117256025786}\n",
            "2025-03-25 11:23:54.168 INFO: Processing datasets for head 'default'\n",
            "2025-03-25 11:23:54.219 INFO: Combining 1 list datasets for head 'default'\n",
            "2025-03-25 11:23:54.253 INFO: Combining 1 list datasets for head 'default_valid'\n",
            "2025-03-25 11:23:54.254 INFO: Combined validation datasets for default\n",
            "2025-03-25 11:23:54.255 INFO: Head 'default' training dataset size: 18\n",
            "2025-03-25 11:23:54.258 INFO: Computing average number of neighbors\n",
            "2025-03-25 11:23:54.577 INFO: Average number of neighbors: 9.923809523809524\n",
            "2025-03-25 11:23:54.579 INFO: During training the following quantities will be reported: energy, forces\n",
            "2025-03-25 11:23:54.580 INFO: ===========MODEL DETAILS===========\n",
            "2025-03-25 11:23:54.623 INFO: Building model\n",
            "2025-03-25 11:23:54.624 INFO: Message passing with 32 channels and max_L=0 (32x0e)\n",
            "2025-03-25 11:23:54.625 INFO: 2 layers, each with correlation order: 3 (body order: 4) and spherical harmonics up to: l=3\n",
            "2025-03-25 11:23:54.625 INFO: 8 radial and 5 basis functions\n",
            "2025-03-25 11:23:54.626 INFO: Radial cutoff: 4.0 A (total receptive field for each atom: 8.0 A)\n",
            "2025-03-25 11:23:54.626 INFO: Distance transform for radial basis functions: None\n",
            "2025-03-25 11:23:54.627 INFO: Hidden irreps: 32x0e\n",
            "2025-03-25 11:23:56.734 INFO: Total number of parameters: 67472\n",
            "2025-03-25 11:23:56.735 INFO: \n",
            "2025-03-25 11:23:56.737 INFO: ===========OPTIMIZER INFORMATION===========\n",
            "2025-03-25 11:23:56.737 INFO: Using ADAM as parameter optimizer\n",
            "2025-03-25 11:23:56.738 INFO: Batch size: 5\n",
            "2025-03-25 11:23:56.739 INFO: Number of gradient updates: 1080\n",
            "2025-03-25 11:23:56.740 INFO: Learning rate: 0.01, weight decay: 5e-07\n",
            "2025-03-25 11:23:56.741 INFO: WeightedEnergyForcesLoss(energy_weight=1.000, forces_weight=100.000)\n",
            "2025-03-25 11:23:56.742 INFO: Stage Two (after 225 epochs) with loss function: WeightedEnergyForcesLoss(energy_weight=1000.000, forces_weight=100.000), with energy weight : 1000.0, forces weight : 100.0 and learning rate : 0.001\n",
            "2025-03-25 11:23:56.841 INFO: Using gradient clipping with tolerance=10.000\n",
            "2025-03-25 11:23:56.842 INFO: \n",
            "2025-03-25 11:23:56.843 INFO: ===========TRAINING===========\n",
            "2025-03-25 11:23:56.844 INFO: Started training, reporting errors on validation set\n",
            "2025-03-25 11:23:56.845 INFO: Loss metrics on validation set\n",
            "2025-03-25 11:24:01.861 INFO: Initial: head: default, loss=37.40605072, RMSE_E_per_atom= 6051.94 meV, RMSE_F= 1775.00 meV / A\n",
            "2025-03-25 11:24:04.895 INFO: Epoch 0: head: default, loss=32.53485076, RMSE_E_per_atom= 5977.34 meV, RMSE_F= 1646.45 meV / A\n",
            "2025-03-25 11:24:07.984 INFO: Epoch 1: head: default, loss=25.04413441, RMSE_E_per_atom= 5765.35 meV, RMSE_F= 1424.05 meV / A\n",
            "2025-03-25 11:24:08.576 INFO: Epoch 2: head: default, loss=24.43607628, RMSE_E_per_atom= 5342.47 meV, RMSE_F= 1398.30 meV / A\n",
            "2025-03-25 11:24:09.042 INFO: Epoch 3: head: default, loss=26.54086403, RMSE_E_per_atom= 5126.11 meV, RMSE_F= 1459.33 meV / A\n",
            "2025-03-25 11:24:09.454 INFO: Epoch 4: head: default, loss=19.96216322, RMSE_E_per_atom= 5205.46 meV, RMSE_F= 1238.61 meV / A\n",
            "2025-03-25 11:24:09.860 INFO: Epoch 5: head: default, loss=17.05116353, RMSE_E_per_atom= 5294.80 meV, RMSE_F= 1122.23 meV / A\n",
            "2025-03-25 11:24:10.266 INFO: Epoch 6: head: default, loss=16.01898707, RMSE_E_per_atom= 5228.44 meV, RMSE_F= 1071.29 meV / A\n",
            "2025-03-25 11:24:10.668 INFO: Epoch 7: head: default, loss=13.39760623, RMSE_E_per_atom= 5180.22 meV, RMSE_F=  957.12 meV / A\n",
            "2025-03-25 11:24:11.067 INFO: Epoch 8: head: default, loss=11.03609041, RMSE_E_per_atom= 5063.50 meV, RMSE_F=  848.80 meV / A\n",
            "2025-03-25 11:24:11.477 INFO: Epoch 9: head: default, loss=11.04780350, RMSE_E_per_atom= 4975.71 meV, RMSE_F=  849.34 meV / A\n",
            "2025-03-25 11:24:11.853 INFO: Epoch 10: head: default, loss=9.32986911, RMSE_E_per_atom= 4837.73 meV, RMSE_F=  771.54 meV / A\n",
            "2025-03-25 11:24:12.249 INFO: Epoch 11: head: default, loss=9.62254493, RMSE_E_per_atom= 4845.55 meV, RMSE_F=  788.76 meV / A\n",
            "2025-03-25 11:24:12.642 INFO: Epoch 12: head: default, loss=8.44271441, RMSE_E_per_atom= 4734.40 meV, RMSE_F=  719.43 meV / A\n",
            "2025-03-25 11:24:13.044 INFO: Epoch 13: head: default, loss=7.04752256, RMSE_E_per_atom= 4745.05 meV, RMSE_F=  626.97 meV / A\n",
            "2025-03-25 11:24:13.463 INFO: Epoch 14: head: default, loss=6.74922899, RMSE_E_per_atom= 4733.45 meV, RMSE_F=  609.03 meV / A\n",
            "2025-03-25 11:24:13.873 INFO: Epoch 15: head: default, loss=7.43741975, RMSE_E_per_atom= 4711.47 meV, RMSE_F=  658.58 meV / A\n",
            "2025-03-25 11:24:14.256 INFO: Epoch 16: head: default, loss=6.37701625, RMSE_E_per_atom= 4684.48 meV, RMSE_F=  583.68 meV / A\n",
            "2025-03-25 11:24:14.682 INFO: Epoch 17: head: default, loss=5.87309984, RMSE_E_per_atom= 4710.59 meV, RMSE_F=  544.06 meV / A\n",
            "2025-03-25 11:24:15.091 INFO: Epoch 18: head: default, loss=5.43941874, RMSE_E_per_atom= 4676.42 meV, RMSE_F=  509.31 meV / A\n",
            "2025-03-25 11:24:15.500 INFO: Epoch 19: head: default, loss=4.91970861, RMSE_E_per_atom= 4613.30 meV, RMSE_F=  469.77 meV / A\n",
            "2025-03-25 11:24:15.895 INFO: Epoch 20: head: default, loss=4.99084551, RMSE_E_per_atom= 4547.06 meV, RMSE_F=  479.68 meV / A\n",
            "2025-03-25 11:24:16.274 INFO: Epoch 21: head: default, loss=4.93401836, RMSE_E_per_atom= 4486.21 meV, RMSE_F=  484.58 meV / A\n",
            "2025-03-25 11:24:16.674 INFO: Epoch 22: head: default, loss=4.99148874, RMSE_E_per_atom= 4448.51 meV, RMSE_F=  489.65 meV / A\n",
            "2025-03-25 11:24:17.058 INFO: Epoch 23: head: default, loss=5.17382030, RMSE_E_per_atom= 4337.06 meV, RMSE_F=  520.38 meV / A\n",
            "2025-03-25 11:24:17.454 INFO: Epoch 24: head: default, loss=4.75088863, RMSE_E_per_atom= 4355.86 meV, RMSE_F=  476.68 meV / A\n",
            "2025-03-25 11:24:17.859 INFO: Epoch 25: head: default, loss=4.45502003, RMSE_E_per_atom= 4263.44 meV, RMSE_F=  458.51 meV / A\n",
            "2025-03-25 11:24:18.254 INFO: Epoch 26: head: default, loss=4.15671302, RMSE_E_per_atom= 4166.02 meV, RMSE_F=  439.03 meV / A\n",
            "2025-03-25 11:24:18.663 INFO: Epoch 27: head: default, loss=3.92030958, RMSE_E_per_atom= 4130.47 meV, RMSE_F=  413.97 meV / A\n",
            "2025-03-25 11:24:19.207 INFO: Epoch 28: head: default, loss=3.89430187, RMSE_E_per_atom= 4112.45 meV, RMSE_F=  412.24 meV / A\n",
            "2025-03-25 11:24:19.738 INFO: Epoch 29: head: default, loss=3.64020044, RMSE_E_per_atom= 3957.62 meV, RMSE_F=  400.60 meV / A\n",
            "2025-03-25 11:24:20.275 INFO: Epoch 30: head: default, loss=3.65298409, RMSE_E_per_atom= 3895.56 meV, RMSE_F=  407.41 meV / A\n",
            "2025-03-25 11:24:20.824 INFO: Epoch 31: head: default, loss=3.79140516, RMSE_E_per_atom= 3860.67 meV, RMSE_F=  428.07 meV / A\n",
            "2025-03-25 11:24:21.209 INFO: Epoch 32: head: default, loss=3.80926400, RMSE_E_per_atom= 3692.16 meV, RMSE_F=  441.52 meV / A\n",
            "2025-03-25 11:24:21.611 INFO: Epoch 33: head: default, loss=3.51858433, RMSE_E_per_atom= 3669.55 meV, RMSE_F=  414.37 meV / A\n",
            "2025-03-25 11:24:22.017 INFO: Epoch 34: head: default, loss=3.12933436, RMSE_E_per_atom= 3528.28 meV, RMSE_F=  382.73 meV / A\n",
            "2025-03-25 11:24:22.419 INFO: Epoch 35: head: default, loss=3.54879583, RMSE_E_per_atom= 3420.08 meV, RMSE_F=  441.21 meV / A\n",
            "2025-03-25 11:24:22.814 INFO: Epoch 36: head: default, loss=3.20947783, RMSE_E_per_atom= 3199.01 meV, RMSE_F=  420.29 meV / A\n",
            "2025-03-25 11:24:23.207 INFO: Epoch 37: head: default, loss=3.07228994, RMSE_E_per_atom= 3134.56 meV, RMSE_F=  411.40 meV / A\n",
            "2025-03-25 11:24:23.620 INFO: Epoch 38: head: default, loss=2.91595216, RMSE_E_per_atom= 3065.07 meV, RMSE_F=  396.49 meV / A\n",
            "2025-03-25 11:24:24.047 INFO: Epoch 39: head: default, loss=2.95213844, RMSE_E_per_atom= 2933.99 meV, RMSE_F=  411.02 meV / A\n",
            "2025-03-25 11:24:24.435 INFO: Epoch 40: head: default, loss=2.35319247, RMSE_E_per_atom= 2827.74 meV, RMSE_F=  350.98 meV / A\n",
            "2025-03-25 11:24:24.849 INFO: Epoch 41: head: default, loss=2.35290807, RMSE_E_per_atom= 2728.79 meV, RMSE_F=  361.20 meV / A\n",
            "2025-03-25 11:24:25.269 INFO: Epoch 42: head: default, loss=2.32101910, RMSE_E_per_atom= 2720.52 meV, RMSE_F=  355.70 meV / A\n",
            "2025-03-25 11:24:25.687 INFO: Epoch 43: head: default, loss=2.54069671, RMSE_E_per_atom= 2655.63 meV, RMSE_F=  386.23 meV / A\n",
            "2025-03-25 11:24:26.089 INFO: Epoch 44: head: default, loss=2.23270608, RMSE_E_per_atom= 2571.42 meV, RMSE_F=  357.15 meV / A\n",
            "2025-03-25 11:24:26.501 INFO: Epoch 45: head: default, loss=2.04416025, RMSE_E_per_atom= 2582.80 meV, RMSE_F=  334.79 meV / A\n",
            "2025-03-25 11:24:26.914 INFO: Epoch 46: head: default, loss=2.44308134, RMSE_E_per_atom= 2470.52 meV, RMSE_F=  386.95 meV / A\n",
            "2025-03-25 11:24:27.294 INFO: Epoch 47: head: default, loss=1.93251244, RMSE_E_per_atom= 2373.58 meV, RMSE_F=  330.92 meV / A\n",
            "2025-03-25 11:24:27.725 INFO: Epoch 48: head: default, loss=2.22644249, RMSE_E_per_atom= 2326.76 meV, RMSE_F=  374.45 meV / A\n",
            "2025-03-25 11:24:28.125 INFO: Epoch 49: head: default, loss=2.02803193, RMSE_E_per_atom= 2103.92 meV, RMSE_F=  360.82 meV / A\n",
            "2025-03-25 11:24:28.515 INFO: Epoch 50: head: default, loss=2.07252073, RMSE_E_per_atom= 1864.30 meV, RMSE_F=  381.53 meV / A\n",
            "2025-03-25 11:24:28.918 INFO: Epoch 51: head: default, loss=3.09240437, RMSE_E_per_atom= 1961.91 meV, RMSE_F=  482.50 meV / A\n",
            "2025-03-25 11:24:29.306 INFO: Epoch 52: head: default, loss=3.62478935, RMSE_E_per_atom= 1967.30 meV, RMSE_F=  530.79 meV / A\n",
            "2025-03-25 11:24:29.689 INFO: Epoch 53: head: default, loss=2.54113206, RMSE_E_per_atom= 1820.08 meV, RMSE_F=  434.18 meV / A\n",
            "2025-03-25 11:24:30.083 INFO: Epoch 54: head: default, loss=2.42762316, RMSE_E_per_atom= 1876.15 meV, RMSE_F=  415.08 meV / A\n",
            "2025-03-25 11:24:30.459 INFO: Epoch 55: head: default, loss=2.52363800, RMSE_E_per_atom= 1809.79 meV, RMSE_F=  430.97 meV / A\n",
            "2025-03-25 11:24:30.909 INFO: Epoch 56: head: default, loss=2.18381395, RMSE_E_per_atom= 1881.99 meV, RMSE_F=  390.73 meV / A\n",
            "2025-03-25 11:24:31.431 INFO: Epoch 57: head: default, loss=2.32085954, RMSE_E_per_atom= 1818.34 meV, RMSE_F=  410.11 meV / A\n",
            "2025-03-25 11:24:32.088 INFO: Epoch 58: head: default, loss=2.16313998, RMSE_E_per_atom= 1892.82 meV, RMSE_F=  388.29 meV / A\n",
            "2025-03-25 11:24:32.679 INFO: Epoch 59: head: default, loss=1.90275195, RMSE_E_per_atom= 1818.16 meV, RMSE_F=  361.93 meV / A\n",
            "2025-03-25 11:24:33.413 INFO: Epoch 60: head: default, loss=2.24401671, RMSE_E_per_atom= 1850.22 meV, RMSE_F=  399.68 meV / A\n",
            "2025-03-25 11:24:33.957 INFO: Epoch 61: head: default, loss=1.83308941, RMSE_E_per_atom= 1763.88 meV, RMSE_F=  356.83 meV / A\n",
            "2025-03-25 11:24:34.531 INFO: Epoch 62: head: default, loss=1.94652957, RMSE_E_per_atom= 1799.26 meV, RMSE_F=  368.72 meV / A\n",
            "2025-03-25 11:24:34.910 INFO: Epoch 63: head: default, loss=1.87925605, RMSE_E_per_atom= 1704.06 meV, RMSE_F=  365.28 meV / A\n",
            "2025-03-25 11:24:35.293 INFO: Epoch 64: head: default, loss=2.02336613, RMSE_E_per_atom= 1744.01 meV, RMSE_F=  380.87 meV / A\n",
            "2025-03-25 11:24:35.710 INFO: Epoch 65: head: default, loss=1.97538420, RMSE_E_per_atom= 1662.88 meV, RMSE_F=  378.11 meV / A\n",
            "2025-03-25 11:24:36.102 INFO: Epoch 66: head: default, loss=1.97065822, RMSE_E_per_atom= 1742.72 meV, RMSE_F=  374.65 meV / A\n",
            "2025-03-25 11:24:36.483 INFO: Epoch 67: head: default, loss=1.77629340, RMSE_E_per_atom= 1622.66 meV, RMSE_F=  355.72 meV / A\n",
            "2025-03-25 11:24:36.887 INFO: Epoch 68: head: default, loss=1.65608883, RMSE_E_per_atom= 1633.32 meV, RMSE_F=  339.37 meV / A\n",
            "2025-03-25 11:24:37.306 INFO: Epoch 69: head: default, loss=1.70336577, RMSE_E_per_atom= 1542.74 meV, RMSE_F=  349.35 meV / A\n",
            "2025-03-25 11:24:37.697 INFO: Epoch 70: head: default, loss=2.01948097, RMSE_E_per_atom= 1585.87 meV, RMSE_F=  387.07 meV / A\n",
            "2025-03-25 11:24:38.093 INFO: Epoch 71: head: default, loss=1.34630385, RMSE_E_per_atom= 1471.03 meV, RMSE_F=  304.08 meV / A\n",
            "2025-03-25 11:24:38.505 INFO: Epoch 72: head: default, loss=1.71774507, RMSE_E_per_atom= 1465.57 meV, RMSE_F=  356.18 meV / A\n",
            "2025-03-25 11:24:38.888 INFO: Epoch 73: head: default, loss=1.68783218, RMSE_E_per_atom= 1382.52 meV, RMSE_F=  353.91 meV / A\n",
            "2025-03-25 11:24:39.281 INFO: Epoch 74: head: default, loss=1.82044476, RMSE_E_per_atom= 1382.65 meV, RMSE_F=  371.15 meV / A\n",
            "2025-03-25 11:24:39.671 INFO: Epoch 75: head: default, loss=1.37183766, RMSE_E_per_atom= 1290.09 meV, RMSE_F=  315.79 meV / A\n",
            "2025-03-25 11:24:40.059 INFO: Epoch 76: head: default, loss=1.36440391, RMSE_E_per_atom= 1344.75 meV, RMSE_F=  316.04 meV / A\n",
            "2025-03-25 11:24:40.449 INFO: Epoch 77: head: default, loss=1.38637533, RMSE_E_per_atom= 1218.53 meV, RMSE_F=  319.02 meV / A\n",
            "2025-03-25 11:24:40.834 INFO: Epoch 78: head: default, loss=1.32831270, RMSE_E_per_atom= 1186.11 meV, RMSE_F=  316.96 meV / A\n",
            "2025-03-25 11:24:41.243 INFO: Epoch 79: head: default, loss=1.24776181, RMSE_E_per_atom= 1168.97 meV, RMSE_F=  303.70 meV / A\n",
            "2025-03-25 11:24:41.639 INFO: Epoch 80: head: default, loss=1.00163807, RMSE_E_per_atom= 1054.63 meV, RMSE_F=  271.59 meV / A\n",
            "2025-03-25 11:24:42.034 INFO: Epoch 81: head: default, loss=1.03722694, RMSE_E_per_atom=  978.45 meV, RMSE_F=  281.77 meV / A\n",
            "2025-03-25 11:24:42.423 INFO: Epoch 82: head: default, loss=1.21165987, RMSE_E_per_atom=  956.50 meV, RMSE_F=  303.47 meV / A\n",
            "2025-03-25 11:24:42.797 INFO: Epoch 83: head: default, loss=0.97801041, RMSE_E_per_atom=  959.12 meV, RMSE_F=  268.28 meV / A\n",
            "2025-03-25 11:24:43.202 INFO: Epoch 84: head: default, loss=1.35347156, RMSE_E_per_atom=  758.47 meV, RMSE_F=  337.38 meV / A\n",
            "2025-03-25 11:24:43.658 INFO: Epoch 85: head: default, loss=1.30462266, RMSE_E_per_atom=  810.83 meV, RMSE_F=  326.58 meV / A\n",
            "2025-03-25 11:24:44.167 INFO: Epoch 86: head: default, loss=2.22162958, RMSE_E_per_atom= 1033.25 meV, RMSE_F=  419.17 meV / A\n",
            "2025-03-25 11:24:44.666 INFO: Epoch 87: head: default, loss=1.35747562, RMSE_E_per_atom=  974.31 meV, RMSE_F=  324.89 meV / A\n",
            "2025-03-25 11:24:45.238 INFO: Epoch 88: head: default, loss=1.27432226, RMSE_E_per_atom=  858.38 meV, RMSE_F=  315.61 meV / A\n",
            "2025-03-25 11:24:45.692 INFO: Epoch 89: head: default, loss=1.16514094, RMSE_E_per_atom=  919.36 meV, RMSE_F=  304.82 meV / A\n",
            "2025-03-25 11:24:46.076 INFO: Epoch 90: head: default, loss=1.27891849, RMSE_E_per_atom=  952.85 meV, RMSE_F=  320.73 meV / A\n",
            "2025-03-25 11:24:46.467 INFO: Epoch 91: head: default, loss=1.18891216, RMSE_E_per_atom=  738.95 meV, RMSE_F=  309.58 meV / A\n",
            "2025-03-25 11:24:46.860 INFO: Epoch 92: head: default, loss=0.91787444, RMSE_E_per_atom=  775.89 meV, RMSE_F=  269.75 meV / A\n",
            "2025-03-25 11:24:47.270 INFO: Epoch 93: head: default, loss=1.09308475, RMSE_E_per_atom=  822.50 meV, RMSE_F=  294.16 meV / A\n",
            "2025-03-25 11:24:47.669 INFO: Epoch 94: head: default, loss=1.01984095, RMSE_E_per_atom=  775.64 meV, RMSE_F=  285.19 meV / A\n",
            "2025-03-25 11:24:48.046 INFO: Epoch 95: head: default, loss=0.94083471, RMSE_E_per_atom=  686.81 meV, RMSE_F=  271.67 meV / A\n",
            "2025-03-25 11:24:48.436 INFO: Epoch 96: head: default, loss=0.84599658, RMSE_E_per_atom=  642.32 meV, RMSE_F=  261.02 meV / A\n",
            "2025-03-25 11:24:48.844 INFO: Epoch 97: head: default, loss=1.03223471, RMSE_E_per_atom=  624.86 meV, RMSE_F=  288.14 meV / A\n",
            "2025-03-25 11:24:49.228 INFO: Epoch 98: head: default, loss=0.81027959, RMSE_E_per_atom=  560.13 meV, RMSE_F=  254.75 meV / A\n",
            "2025-03-25 11:24:49.647 INFO: Epoch 99: head: default, loss=1.09311981, RMSE_E_per_atom=  472.26 meV, RMSE_F=  303.37 meV / A\n",
            "2025-03-25 11:24:50.035 INFO: Epoch 100: head: default, loss=1.03872524, RMSE_E_per_atom=  397.34 meV, RMSE_F=  294.28 meV / A\n",
            "2025-03-25 11:24:50.416 INFO: Epoch 101: head: default, loss=1.02574059, RMSE_E_per_atom=  495.16 meV, RMSE_F=  291.00 meV / A\n",
            "2025-03-25 11:24:50.810 INFO: Epoch 102: head: default, loss=0.99998920, RMSE_E_per_atom=  496.07 meV, RMSE_F=  285.91 meV / A\n",
            "2025-03-25 11:24:51.199 INFO: Epoch 103: head: default, loss=0.85373683, RMSE_E_per_atom=  414.92 meV, RMSE_F=  266.99 meV / A\n",
            "2025-03-25 11:24:51.592 INFO: Epoch 104: head: default, loss=1.20570557, RMSE_E_per_atom=  436.25 meV, RMSE_F=  316.63 meV / A\n",
            "2025-03-25 11:24:51.972 INFO: Epoch 105: head: default, loss=1.04996944, RMSE_E_per_atom=  551.12 meV, RMSE_F=  289.24 meV / A\n",
            "2025-03-25 11:24:52.350 INFO: Epoch 106: head: default, loss=0.99763068, RMSE_E_per_atom=  485.53 meV, RMSE_F=  291.39 meV / A\n",
            "2025-03-25 11:24:52.742 INFO: Epoch 107: head: default, loss=0.90510105, RMSE_E_per_atom=  441.90 meV, RMSE_F=  273.03 meV / A\n",
            "2025-03-25 11:24:53.127 INFO: Epoch 108: head: default, loss=0.84353460, RMSE_E_per_atom=  422.50 meV, RMSE_F=  266.34 meV / A\n",
            "2025-03-25 11:24:53.512 INFO: Epoch 109: head: default, loss=0.79074932, RMSE_E_per_atom=  436.08 meV, RMSE_F=  250.02 meV / A\n",
            "2025-03-25 11:24:53.930 INFO: Epoch 110: head: default, loss=0.93509405, RMSE_E_per_atom=  411.34 meV, RMSE_F=  274.73 meV / A\n",
            "2025-03-25 11:24:54.308 INFO: Epoch 111: head: default, loss=0.84603157, RMSE_E_per_atom=  400.30 meV, RMSE_F=  267.17 meV / A\n",
            "2025-03-25 11:24:54.698 INFO: Epoch 112: head: default, loss=0.94710173, RMSE_E_per_atom=  400.59 meV, RMSE_F=  280.44 meV / A\n",
            "2025-03-25 11:24:55.078 INFO: Epoch 113: head: default, loss=0.70020361, RMSE_E_per_atom=  417.77 meV, RMSE_F=  237.48 meV / A\n",
            "2025-03-25 11:24:55.526 INFO: Epoch 114: head: default, loss=0.79842731, RMSE_E_per_atom=  299.39 meV, RMSE_F=  257.23 meV / A\n",
            "2025-03-25 11:24:56.059 INFO: Epoch 115: head: default, loss=0.63664493, RMSE_E_per_atom=  349.71 meV, RMSE_F=  225.95 meV / A\n",
            "2025-03-25 11:24:56.567 INFO: Epoch 116: head: default, loss=0.84280385, RMSE_E_per_atom=  381.92 meV, RMSE_F=  261.21 meV / A\n",
            "2025-03-25 11:24:57.136 INFO: Epoch 117: head: default, loss=0.78241053, RMSE_E_per_atom=  312.16 meV, RMSE_F=  252.63 meV / A\n",
            "2025-03-25 11:24:57.605 INFO: Epoch 118: head: default, loss=0.74020048, RMSE_E_per_atom=  289.75 meV, RMSE_F=  244.93 meV / A\n",
            "2025-03-25 11:24:58.022 INFO: Epoch 119: head: default, loss=1.09517135, RMSE_E_per_atom=  316.68 meV, RMSE_F=  304.50 meV / A\n",
            "2025-03-25 11:24:58.409 INFO: Epoch 120: head: default, loss=0.99511608, RMSE_E_per_atom=  316.94 meV, RMSE_F=  285.11 meV / A\n",
            "2025-03-25 11:24:58.798 INFO: Epoch 121: head: default, loss=0.96303092, RMSE_E_per_atom=  267.83 meV, RMSE_F=  285.93 meV / A\n",
            "2025-03-25 11:24:59.189 INFO: Epoch 122: head: default, loss=1.10745444, RMSE_E_per_atom=  294.44 meV, RMSE_F=  304.29 meV / A\n",
            "2025-03-25 11:24:59.578 INFO: Epoch 123: head: default, loss=0.86665532, RMSE_E_per_atom=  393.98 meV, RMSE_F=  271.78 meV / A\n",
            "2025-03-25 11:24:59.965 INFO: Epoch 124: head: default, loss=0.84788913, RMSE_E_per_atom=  329.34 meV, RMSE_F=  262.99 meV / A\n",
            "2025-03-25 11:25:00.349 INFO: Epoch 125: head: default, loss=0.78151555, RMSE_E_per_atom=  347.00 meV, RMSE_F=  254.68 meV / A\n",
            "2025-03-25 11:25:00.746 INFO: Epoch 126: head: default, loss=0.90116748, RMSE_E_per_atom=  363.59 meV, RMSE_F=  272.51 meV / A\n",
            "2025-03-25 11:25:01.143 INFO: Epoch 127: head: default, loss=0.84073081, RMSE_E_per_atom=  398.41 meV, RMSE_F=  263.48 meV / A\n",
            "2025-03-25 11:25:01.543 INFO: Epoch 128: head: default, loss=0.61423555, RMSE_E_per_atom=  306.57 meV, RMSE_F=  222.39 meV / A\n",
            "2025-03-25 11:25:01.976 INFO: Epoch 129: head: default, loss=0.78379189, RMSE_E_per_atom=  240.22 meV, RMSE_F=  259.33 meV / A\n",
            "2025-03-25 11:25:02.369 INFO: Epoch 130: head: default, loss=1.18666358, RMSE_E_per_atom=  381.50 meV, RMSE_F=  315.96 meV / A\n",
            "2025-03-25 11:25:02.755 INFO: Epoch 131: head: default, loss=0.85954335, RMSE_E_per_atom=  344.38 meV, RMSE_F=  264.41 meV / A\n",
            "2025-03-25 11:25:03.147 INFO: Epoch 132: head: default, loss=0.97644936, RMSE_E_per_atom=  213.20 meV, RMSE_F=  286.28 meV / A\n",
            "2025-03-25 11:25:03.525 INFO: Epoch 133: head: default, loss=0.84563332, RMSE_E_per_atom=  318.74 meV, RMSE_F=  264.90 meV / A\n",
            "2025-03-25 11:25:03.913 INFO: Epoch 134: head: default, loss=0.99268604, RMSE_E_per_atom=  379.19 meV, RMSE_F=  283.69 meV / A\n",
            "2025-03-25 11:25:04.290 INFO: Epoch 135: head: default, loss=0.61925896, RMSE_E_per_atom=  347.71 meV, RMSE_F=  224.01 meV / A\n",
            "2025-03-25 11:25:04.667 INFO: Epoch 136: head: default, loss=0.62804974, RMSE_E_per_atom=  298.99 meV, RMSE_F=  226.30 meV / A\n",
            "2025-03-25 11:25:05.058 INFO: Epoch 137: head: default, loss=0.66448522, RMSE_E_per_atom=  346.09 meV, RMSE_F=  227.95 meV / A\n",
            "2025-03-25 11:25:05.438 INFO: Epoch 138: head: default, loss=0.59536770, RMSE_E_per_atom=  295.87 meV, RMSE_F=  217.78 meV / A\n",
            "2025-03-25 11:25:05.835 INFO: Epoch 139: head: default, loss=0.74643117, RMSE_E_per_atom=  181.87 meV, RMSE_F=  249.04 meV / A\n",
            "2025-03-25 11:25:06.235 INFO: Epoch 140: head: default, loss=0.69217477, RMSE_E_per_atom=  281.63 meV, RMSE_F=  236.93 meV / A\n",
            "2025-03-25 11:25:06.605 INFO: Epoch 141: head: default, loss=0.57131874, RMSE_E_per_atom=  183.91 meV, RMSE_F=  214.45 meV / A\n",
            "2025-03-25 11:25:07.014 INFO: Epoch 142: head: default, loss=0.79119925, RMSE_E_per_atom=  205.68 meV, RMSE_F=  252.22 meV / A\n",
            "2025-03-25 11:25:07.408 INFO: Epoch 143: head: default, loss=0.75760913, RMSE_E_per_atom=  228.87 meV, RMSE_F=  250.98 meV / A\n",
            "2025-03-25 11:25:07.944 INFO: Epoch 144: head: default, loss=0.80018005, RMSE_E_per_atom=  207.08 meV, RMSE_F=  254.83 meV / A\n",
            "2025-03-25 11:25:08.436 INFO: Epoch 145: head: default, loss=0.67556673, RMSE_E_per_atom=  201.85 meV, RMSE_F=  234.81 meV / A\n",
            "2025-03-25 11:25:09.477 INFO: Epoch 146: head: default, loss=0.80062106, RMSE_E_per_atom=  277.44 meV, RMSE_F=  258.41 meV / A\n",
            "2025-03-25 11:25:10.139 INFO: Epoch 147: head: default, loss=0.72856095, RMSE_E_per_atom=  192.98 meV, RMSE_F=  243.93 meV / A\n",
            "2025-03-25 11:25:10.639 INFO: Epoch 148: head: default, loss=0.72298322, RMSE_E_per_atom=  267.55 meV, RMSE_F=  244.10 meV / A\n",
            "2025-03-25 11:25:11.182 INFO: Epoch 149: head: default, loss=0.72373138, RMSE_E_per_atom=  275.15 meV, RMSE_F=  243.64 meV / A\n",
            "2025-03-25 11:25:11.564 INFO: Epoch 150: head: default, loss=0.73514902, RMSE_E_per_atom=  315.02 meV, RMSE_F=  244.46 meV / A\n",
            "2025-03-25 11:25:11.938 INFO: Epoch 151: head: default, loss=0.67400990, RMSE_E_per_atom=  296.37 meV, RMSE_F=  230.96 meV / A\n",
            "2025-03-25 11:25:12.328 INFO: Epoch 152: head: default, loss=0.62009251, RMSE_E_per_atom=  302.82 meV, RMSE_F=  221.24 meV / A\n",
            "2025-03-25 11:25:12.710 INFO: Epoch 153: head: default, loss=0.77325630, RMSE_E_per_atom=  312.35 meV, RMSE_F=  252.17 meV / A\n",
            "2025-03-25 11:25:13.101 INFO: Epoch 154: head: default, loss=0.76830981, RMSE_E_per_atom=  309.80 meV, RMSE_F=  254.61 meV / A\n",
            "2025-03-25 11:25:13.511 INFO: Epoch 155: head: default, loss=0.62861538, RMSE_E_per_atom=  210.77 meV, RMSE_F=  225.52 meV / A\n",
            "2025-03-25 11:25:13.900 INFO: Epoch 156: head: default, loss=0.58833584, RMSE_E_per_atom=  236.99 meV, RMSE_F=  213.53 meV / A\n",
            "2025-03-25 11:25:14.287 INFO: Epoch 157: head: default, loss=0.59294395, RMSE_E_per_atom=  263.95 meV, RMSE_F=  216.29 meV / A\n",
            "2025-03-25 11:25:14.675 INFO: Epoch 158: head: default, loss=0.83641914, RMSE_E_per_atom=  227.20 meV, RMSE_F=  259.18 meV / A\n",
            "2025-03-25 11:25:15.061 INFO: Epoch 159: head: default, loss=0.57653779, RMSE_E_per_atom=  239.83 meV, RMSE_F=  213.06 meV / A\n",
            "2025-03-25 11:25:15.458 INFO: Epoch 160: head: default, loss=0.55898043, RMSE_E_per_atom=  223.86 meV, RMSE_F=  213.92 meV / A\n",
            "2025-03-25 11:25:15.854 INFO: Epoch 161: head: default, loss=0.54755550, RMSE_E_per_atom=  221.70 meV, RMSE_F=  208.01 meV / A\n",
            "2025-03-25 11:25:16.267 INFO: Epoch 162: head: default, loss=0.62520979, RMSE_E_per_atom=  212.61 meV, RMSE_F=  225.75 meV / A\n",
            "2025-03-25 11:25:16.640 INFO: Epoch 163: head: default, loss=0.53318113, RMSE_E_per_atom=  204.15 meV, RMSE_F=  206.85 meV / A\n",
            "2025-03-25 11:25:17.042 INFO: Epoch 164: head: default, loss=0.56183593, RMSE_E_per_atom=  177.74 meV, RMSE_F=  210.76 meV / A\n",
            "2025-03-25 11:25:17.428 INFO: Epoch 165: head: default, loss=0.61331136, RMSE_E_per_atom=  183.52 meV, RMSE_F=  225.14 meV / A\n",
            "2025-03-25 11:25:17.807 INFO: Epoch 166: head: default, loss=0.61963088, RMSE_E_per_atom=  182.50 meV, RMSE_F=  218.76 meV / A\n",
            "2025-03-25 11:25:18.179 INFO: Epoch 167: head: default, loss=0.58577901, RMSE_E_per_atom=  201.32 meV, RMSE_F=  215.82 meV / A\n",
            "2025-03-25 11:25:18.564 INFO: Epoch 168: head: default, loss=0.74882033, RMSE_E_per_atom=  195.84 meV, RMSE_F=  245.10 meV / A\n",
            "2025-03-25 11:25:18.941 INFO: Epoch 169: head: default, loss=0.76029301, RMSE_E_per_atom=  184.63 meV, RMSE_F=  253.80 meV / A\n",
            "2025-03-25 11:25:19.332 INFO: Epoch 170: head: default, loss=0.98324085, RMSE_E_per_atom=  244.43 meV, RMSE_F=  282.53 meV / A\n",
            "2025-03-25 11:25:19.812 INFO: Epoch 171: head: default, loss=0.76795372, RMSE_E_per_atom=  271.06 meV, RMSE_F=  248.27 meV / A\n",
            "2025-03-25 11:25:20.306 INFO: Epoch 172: head: default, loss=0.91005404, RMSE_E_per_atom=  198.92 meV, RMSE_F=  276.37 meV / A\n",
            "2025-03-25 11:25:20.821 INFO: Epoch 173: head: default, loss=0.75116006, RMSE_E_per_atom=  261.45 meV, RMSE_F=  250.23 meV / A\n",
            "2025-03-25 11:25:21.384 INFO: Epoch 174: head: default, loss=0.72238053, RMSE_E_per_atom=  288.93 meV, RMSE_F=  240.40 meV / A\n",
            "2025-03-25 11:25:21.786 INFO: Epoch 175: head: default, loss=0.84273171, RMSE_E_per_atom=  214.18 meV, RMSE_F=  266.02 meV / A\n",
            "2025-03-25 11:25:22.166 INFO: Epoch 176: head: default, loss=0.59341681, RMSE_E_per_atom=  280.46 meV, RMSE_F=  214.87 meV / A\n",
            "2025-03-25 11:25:22.550 INFO: Epoch 177: head: default, loss=0.80351244, RMSE_E_per_atom=  250.23 meV, RMSE_F=  257.82 meV / A\n",
            "2025-03-25 11:25:22.941 INFO: Epoch 178: head: default, loss=0.52604746, RMSE_E_per_atom=  259.38 meV, RMSE_F=  201.21 meV / A\n",
            "2025-03-25 11:25:23.362 INFO: Epoch 179: head: default, loss=0.55192726, RMSE_E_per_atom=  238.01 meV, RMSE_F=  208.78 meV / A\n",
            "2025-03-25 11:25:23.770 INFO: Epoch 180: head: default, loss=0.60761375, RMSE_E_per_atom=  238.01 meV, RMSE_F=  222.59 meV / A\n",
            "2025-03-25 11:25:24.171 INFO: Epoch 181: head: default, loss=0.79041522, RMSE_E_per_atom=  237.53 meV, RMSE_F=  254.50 meV / A\n",
            "2025-03-25 11:25:24.569 INFO: Epoch 182: head: default, loss=0.56337143, RMSE_E_per_atom=  175.58 meV, RMSE_F=  214.06 meV / A\n",
            "2025-03-25 11:25:24.963 INFO: Epoch 183: head: default, loss=0.59630575, RMSE_E_per_atom=  172.25 meV, RMSE_F=  217.93 meV / A\n",
            "2025-03-25 11:25:25.350 INFO: Epoch 184: head: default, loss=0.65784466, RMSE_E_per_atom=  208.73 meV, RMSE_F=  228.17 meV / A\n",
            "2025-03-25 11:25:25.745 INFO: Epoch 185: head: default, loss=0.49996785, RMSE_E_per_atom=  189.56 meV, RMSE_F=  196.89 meV / A\n",
            "2025-03-25 11:25:26.141 INFO: Epoch 186: head: default, loss=0.62321983, RMSE_E_per_atom=  240.31 meV, RMSE_F=  223.01 meV / A\n",
            "2025-03-25 11:25:26.519 INFO: Epoch 187: head: default, loss=0.74441953, RMSE_E_per_atom=  204.90 meV, RMSE_F=  242.64 meV / A\n",
            "2025-03-25 11:25:26.900 INFO: Epoch 188: head: default, loss=0.48244501, RMSE_E_per_atom=  200.34 meV, RMSE_F=  196.18 meV / A\n",
            "2025-03-25 11:25:27.296 INFO: Epoch 189: head: default, loss=0.65440763, RMSE_E_per_atom=  190.23 meV, RMSE_F=  228.99 meV / A\n",
            "2025-03-25 11:25:27.685 INFO: Epoch 190: head: default, loss=0.61069175, RMSE_E_per_atom=  181.68 meV, RMSE_F=  223.32 meV / A\n",
            "2025-03-25 11:25:28.093 INFO: Epoch 191: head: default, loss=0.65477500, RMSE_E_per_atom=  194.61 meV, RMSE_F=  229.67 meV / A\n",
            "2025-03-25 11:25:28.472 INFO: Epoch 192: head: default, loss=0.85168964, RMSE_E_per_atom=  190.34 meV, RMSE_F=  264.81 meV / A\n",
            "2025-03-25 11:25:28.863 INFO: Epoch 193: head: default, loss=0.58342235, RMSE_E_per_atom=  228.30 meV, RMSE_F=  218.20 meV / A\n",
            "2025-03-25 11:25:29.243 INFO: Epoch 194: head: default, loss=0.47896404, RMSE_E_per_atom=  201.18 meV, RMSE_F=  198.47 meV / A\n",
            "2025-03-25 11:25:29.645 INFO: Epoch 195: head: default, loss=0.61259210, RMSE_E_per_atom=  157.30 meV, RMSE_F=  227.76 meV / A\n",
            "2025-03-25 11:25:30.029 INFO: Epoch 196: head: default, loss=0.67774281, RMSE_E_per_atom=  227.34 meV, RMSE_F=  236.29 meV / A\n",
            "2025-03-25 11:25:30.402 INFO: Epoch 197: head: default, loss=0.76191815, RMSE_E_per_atom=  210.46 meV, RMSE_F=  250.29 meV / A\n",
            "2025-03-25 11:25:30.803 INFO: Epoch 198: head: default, loss=0.86708712, RMSE_E_per_atom=  161.43 meV, RMSE_F=  264.16 meV / A\n",
            "2025-03-25 11:25:31.190 INFO: Epoch 199: head: default, loss=1.09684364, RMSE_E_per_atom=  287.76 meV, RMSE_F=  310.28 meV / A\n",
            "2025-03-25 11:25:31.627 INFO: Epoch 200: head: default, loss=1.17846343, RMSE_E_per_atom=  286.73 meV, RMSE_F=  312.99 meV / A\n"
          ]
        }
      ],
      "source": [
        "train_mace(\"config/config-03.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyJtdwaIxNVK"
      },
      "outputs": [],
      "source": [
        "#remove checkpoints since they may cause errors on retraining a model with the same name but a different architecture\n",
        "import glob\n",
        "import os\n",
        "for file in glob.glob(\"MACE_models/*.pt\"):\n",
        "    os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ij5FnzxNVL"
      },
      "source": [
        "Notice, we are getting substantially larger errors than before. Now, let's run some dynamics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Y0XqKCxNVL"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "from ase import units\n",
        "from ase.md.langevin import Langevin\n",
        "from ase.md.velocitydistribution import Stationary, ZeroRotation, MaxwellBoltzmannDistribution\n",
        "from aseMolec import extAtoms as ea\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "np.random.seed(701) #just making sure the MD failure is reproducible\n",
        "\n",
        "def simpleMD(init_conf, temp, calc, fname, s, T):\n",
        "    init_conf.set_calculator(calc)\n",
        "\n",
        "    #initialize the temperature\n",
        "\n",
        "    MaxwellBoltzmannDistribution(init_conf, temperature_K=300) #initialize temperature at 300\n",
        "    Stationary(init_conf)\n",
        "    ZeroRotation(init_conf)\n",
        "\n",
        "    dyn = Langevin(init_conf, 1.0*units.fs, temperature_K=temp, friction=0.1) #drive system to desired temperature\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "    time_fs = []\n",
        "    temperature = []\n",
        "    energies = []\n",
        "\n",
        "    #remove previously stored trajectory with the same name\n",
        "    os.system('rm -rfv '+fname)\n",
        "\n",
        "    fig, ax = pl.subplots(2, 1, figsize=(6,6), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "    def write_frame():\n",
        "            dyn.atoms.info['energy_mace'] = dyn.atoms.get_potential_energy()\n",
        "            dyn.atoms.arrays['force_mace'] = dyn.atoms.calc.get_forces()\n",
        "            dyn.atoms.write(fname, append=True)\n",
        "            time_fs.append(dyn.get_time()/units.fs)\n",
        "            temperature.append(dyn.atoms.get_temperature())\n",
        "            energies.append(dyn.atoms.get_potential_energy()/len(dyn.atoms))\n",
        "\n",
        "            ax[0].plot(np.array(time_fs), np.array(energies), color=\"b\")\n",
        "            ax[0].set_ylabel('E (eV/atom)')\n",
        "\n",
        "            # plot the temperature of the system as subplots\n",
        "            ax[1].plot(np.array(time_fs), temperature, color=\"r\")\n",
        "            ax[1].set_ylabel('T (K)')\n",
        "            ax[1].set_xlabel('Time (fs)')\n",
        "\n",
        "            display.clear_output(wait=True)\n",
        "            display.display(pl.gcf())\n",
        "            time.sleep(0.01)\n",
        "\n",
        "    dyn.attach(write_frame, interval=s)\n",
        "    t0 = time.time()\n",
        "    dyn.run(T)\n",
        "    t1 = time.time()\n",
        "    print(\"MD finished in {0:.2f} minutes!\".format((t1-t0)/60))\n",
        "\n",
        "#let us start with a single molecule\n",
        "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
        "\n",
        "#we can use MACE as a calculator in ASE!\n",
        "from mace.calculators import MACECalculator\n",
        "mace_calc = MACECalculator(model_paths=['MACE_models/mace02_com1_run-123_stagetwo.model'], device='cuda')\n",
        "\n",
        "simpleMD(init_conf, temp=1200, calc=mace_calc, fname='moldyn/mace02_md.xyz', s=10, T=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9elyP0FxNVM"
      },
      "source": [
        "Depending on the random seed for the MD, you may see different things. At first sight, the energy against time doesn't look too bad, although the long time scale wandering of the energy is a little weird. Lets look at the trajectory. You might even see an explosion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22uVfg2UxNVM"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "from x3dase.visualize import view_x3d_n\n",
        "\n",
        "traj = read('moldyn/mace02_md.xyz', ':')\n",
        "view_x3d_n(traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbdTtPTxNVN"
      },
      "source": [
        "If you go to the end of the trajectory, you should find that the bond angles are actually very strange - it looks unphsyical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwFdVZGSxNVN"
      },
      "source": [
        "### 1.2 Identify the problem and expand training\n",
        "\n",
        "Something doesn't look right with the hydrogen atoms. Let's re-evaluate the first 100 steps from the trajectory on the reference XTB potential energy surface and then plot it against MACE energy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdwunhD4xNVN"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "from tqdm import tqdm\n",
        "from xtb.ase.calculator import XTB\n",
        "xtb_calc = XTB(method=\"GFN2-xTB\")\n",
        "\n",
        "#compute true reference XTB values\n",
        "print(\"Evaluating MACE configurations with XTB\")\n",
        "traj = read('moldyn/mace02_md.xyz', ':')\n",
        "for at in tqdm(traj[:100]):\n",
        "    at.calc = None\n",
        "    at.calc = xtb_calc\n",
        "    at.info['energy_xtb'] = at.get_potential_energy()\n",
        "    at.arrays['forces_xtb'] = at.get_forces()\n",
        "    at.calc = None\n",
        "\n",
        "write('data/mace02_md_100_xtb.xyz', traj[:100]) #save full result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9lNJVNbxNVN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from aseMolec import extAtoms as ea\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "traj = read('data/mace02_md_100_xtb.xyz', ':')\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_xtb', peratom=True), label='XTB')\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_mace', peratom=True), label='MACE')\n",
        "plt.legend()\n",
        "plt.xlabel('Time (fs)')\n",
        "plt.ylabel('Total Energy per Atom (eV)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V835Pt7KxNVN"
      },
      "source": [
        "Indeed, at around frame 45 the XTB energy diverges, because MACE finds an unphysical config. With older potentials, at this point the MD would explode, but because MACE is much smoother the simulation keeps going, albeit generating the wrong dynamics. Let's take three of these failed configs, add them back to the training set and refit a new model. This is called iterative training:\n",
        "![alt text](https://github.com/imagdau/Tutorials/blob/main/figures/iterative_training.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0qytkOCxNVO"
      },
      "outputs": [],
      "source": [
        "db = read('data/solvent_xtb_train_20.xyz', ':')\n",
        "db += traj[40:100:5] #add failed configs to the training set\n",
        "write('data/solvent_xtb_train_23_gen1.xyz', db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU0SLvwFD2yK"
      },
      "source": [
        "A good exercise is to try to pick the configs that have the largest error on forces and energies. Try coding it yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gbxj436xNVO"
      },
      "source": [
        "### 1.3 Train a new MACE model and run MD again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TirW5fX-D2yK"
      },
      "outputs": [],
      "source": [
        "%%writefile config/config-04.yml\n",
        "\n",
        "model: \"MACE\"\n",
        "num_channels: 32\n",
        "max_L: 0\n",
        "r_max: 4.0\n",
        "name: \"mace02_com1_gen1\"\n",
        "model_dir: \"MACE_models\"\n",
        "log_dir: \"MACE_models\"\n",
        "checkpoints_dir: \"MACE_models\"\n",
        "results_dir: \"MACE_models\"\n",
        "train_file: \"data/solvent_xtb_train_23_gen1.xyz\"\n",
        "valid_file: \"data/solvent_xtb_train_50.xyz\"\n",
        "test_file: \"data/solvent_xtb_test.xyz\"\n",
        "energy_key: \"energy_xtb\"\n",
        "forces_key: \"forces_xtb\"\n",
        "device: cuda\n",
        "batch_size: 10\n",
        "max_num_epochs: 500\n",
        "swa: True\n",
        "seed: 123\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR1oyfPfD2yK"
      },
      "outputs": [],
      "source": [
        "train_mace(\"config/config-04.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knsX6u-ZxNVO"
      },
      "outputs": [],
      "source": [
        "#remove checkpoints since they may cause errors on retraining a model with the same name but a different architecture\n",
        "import glob\n",
        "import os\n",
        "for file in glob.glob(\"MACE_models/*.pt\"):\n",
        "    os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfYqcls4xNVO"
      },
      "source": [
        "For some reason the energy error on the training set is now huge - can you work out why this is?\n",
        "\n",
        "What does this imply about how we do iterative training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyJ_sBJTxNVO"
      },
      "outputs": [],
      "source": [
        "mace_calc = MACECalculator(model_paths=['MACE_models/mace02_com1_gen1_run-123_stagetwo.model'], device='cuda')\n",
        "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
        "simpleMD(init_conf, temp=1200, calc=mace_calc, fname='moldyn/mace02_md_gen1.xyz', s=10, T=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDR3fOAVxNVO"
      },
      "outputs": [],
      "source": [
        "traj = read('moldyn/mace02_md_gen1.xyz', ':')\n",
        "view_x3d_n(traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuaTYEsjxNVP"
      },
      "source": [
        "Great! The dynamics is already looking better, however its hard to tell if it is really correct. To do this we cuold look at the radial distribution function compared to a ground truth trajectory, but if the ground truth is too expensive its not so easy.\n",
        "\n",
        "If we have reason to believe the model is wrong, we could continue the iterative process and gradually improve the potential. This is an arduous process, because we need to carefully investigate the trajectories and decide which configs to add back to training. We could instead automate this protocol by predicting errors on the fly and picking configs which are not well predicted: this is called active learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpH3OgAyxNVP"
      },
      "source": [
        "## 2. Active Learning with MACE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFMwXevOxNVP"
      },
      "source": [
        "### 2.1 Preparing a committee of models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzmSnYbAxNVP"
      },
      "source": [
        "We can compute errors by evaluating the reference energy and forces (in our case XTB) and computing the difference to MACE predictions. In real research applications, this can be very expensive to evaluate depending on the reference level of theory. Alternatively, we can estimate errors based on a committee of models. Let's train a committee of MACE models by adding some randomness to the optimization process. We can achieve this by changing the `--seed`. We already have a model, we will fit two more, on the same data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C7jn1B8D2yM"
      },
      "outputs": [],
      "source": [
        "%%writefile config/config-05.yml\n",
        "\n",
        "model: \"MACE\"\n",
        "num_channels: 32\n",
        "max_L: 0\n",
        "r_max: 4.0\n",
        "name: \"mace02_com2\"\n",
        "model_dir: \"MACE_models\"\n",
        "log_dir: \"MACE_models\"\n",
        "checkpoints_dir: \"MACE_models\"\n",
        "results_dir: \"MACE_models\"\n",
        "train_file: \"data/solvent_xtb_train_23_gen1.xyz\"\n",
        "valid_file: \"data/solvent_xtb_train_50.xyz\"\n",
        "test_file: \"data/solvent_xtb_test.xyz\"\n",
        "energy_key: \"energy_xtb\"\n",
        "forces_key: \"forces_xtb\"\n",
        "device: cuda\n",
        "batch_size: 10\n",
        "max_num_epochs: 500\n",
        "swa: True\n",
        "seed: 345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMDC9wBWD2yM"
      },
      "outputs": [],
      "source": [
        "%%writefile config/config-06.yml\n",
        "\n",
        "model: \"MACE\"\n",
        "num_channels: 32\n",
        "max_L: 0\n",
        "r_max: 4.0\n",
        "name: \"mace02_com3\"\n",
        "model_dir: \"MACE_models\"\n",
        "log_dir: \"MACE_models\"\n",
        "checkpoints_dir: \"MACE_models\"\n",
        "results_dir: \"MACE_models\"\n",
        "train_file: \"data/solvent_xtb_train_23_gen1.xyz\"\n",
        "valid_file: \"data/solvent_xtb_train_50.xyz\"\n",
        "test_file: \"data/solvent_xtb_test.xyz\"\n",
        "energy_key: \"energy_xtb\"\n",
        "forces_key: \"forces_xtb\"\n",
        "device: cuda\n",
        "batch_size: 10\n",
        "max_num_epochs: 500\n",
        "swa: True\n",
        "seed: 567"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-d7doFND2yM"
      },
      "outputs": [],
      "source": [
        "train_mace(\"config/config-05.yml\")\n",
        "train_mace(\"config/config-06.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoL5JoLExNVP"
      },
      "outputs": [],
      "source": [
        "#remove checkpoints since they may cause errors on retraining a model with the same name but a different architecture\n",
        "import glob\n",
        "import os\n",
        "for file in glob.glob(\"MACE_models/*.pt\"):\n",
        "    os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09GP4CZVxNVP"
      },
      "source": [
        "Perfect, we have two new models. Let's start by testing the commitee on the first 100 frames of the first trajectory we generated. The `MACECalculator` can conveniently take a list of calculators as input and will compute separate energies from each calculator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2SaupbgxNVP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from ase.io import read\n",
        "from aseMolec import extAtoms as ea\n",
        "from matplotlib import pyplot as plt\n",
        "from mace.calculators import MACECalculator\n",
        "from tqdm import tqdm\n",
        "\n",
        "model_paths = ['MACE_models/mace02_com3_run-567_stagetwo.model',\n",
        "               'MACE_models/mace02_com2_run-345_stagetwo.model',\n",
        "               'MACE_models/mace02_com1_gen1_run-123_stagetwo.model']\n",
        "mace_calcs = MACECalculator(model_paths=model_paths, device='cuda')\n",
        "\n",
        "traj = read('data/mace02_md_100_xtb.xyz', ':')\n",
        "for at in tqdm(traj):\n",
        "    at.calc = mace_calcs\n",
        "    engs = at.get_potential_energies()\n",
        "    at.info['energy_mace_1'] = at.info.pop('energy_mace') #rename value obtained with first member of the committee\n",
        "    at.info['energy_mace_2'] = engs[1]\n",
        "    at.info['energy_mace_3'] = engs[2]\n",
        "    at.info['variance'] = np.std(engs)\n",
        "    at.info['average_mace_energy'] = np.average(engs)\n",
        "    at.info['true_error'] = np.abs(at.info['average_mace_energy'] - at.info['energy_xtb'])\n",
        "\n",
        "#Let's check the energies of the MACE committee vs XTB energy\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_xtb', peratom=True), label='XTB')\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_mace_1', peratom=True), label='MACE_1')\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_mace_2', peratom=True), label='MACE_2')\n",
        "plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'energy_mace_3', peratom=True), label='MACE_3')\n",
        "plt.legend()\n",
        "plt.xlabel('Time (fs)')\n",
        "plt.ylabel('Energy per Atom (eV)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'variance', peratom=True), label='committee variance')\n",
        "#plt.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'true_error', peratom=True), label='error w.r.t XTB')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "ax1.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'variance', peratom=True), label='committee variance', color='tab:blue')\n",
        "#ax2.plot(np.arange(len(traj)), ea.get_prop(traj, 'info', 'true_error', peratom=True), label='error w.r.t XTB', color='tab:orange')\n",
        "\n",
        "ax1.set_xlabel('time (fs)')\n",
        "ax1.set_ylabel('committee energy variance', color='tab:blue')\n",
        "#ax2.set_ylabel('error w.r.t XTB', color='tab:orange')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yXhlCtVxNVQ"
      },
      "source": [
        "Notice how the variance (disagreement between models) increases around the same config where the true error with respect to XTB diverges. This is good news because it indicates the variance is a good proxy for true error.\n",
        "\n",
        "Now we can run dynamics with a commitee of models and monitor the variance in the energy prediction. Because XTB is cheap enough we can also compare that variance with the true error. Do they correlate?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPX9TP7fxNVQ"
      },
      "source": [
        "### 2.2 Running MD with the MACE committee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOSnpIJUxNVQ"
      },
      "outputs": [],
      "source": [
        "from aseMolec import extAtoms as ea\n",
        "from ase import units\n",
        "from ase.md.langevin import Langevin\n",
        "from ase.md.velocitydistribution import Stationary, ZeroRotation, MaxwellBoltzmannDistribution\n",
        "from ase.io import read, write\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "from mace.calculators import MACECalculator\n",
        "from xtb.ase.calculator import XTB\n",
        "\n",
        "model_paths = ['MACE_models/mace02_com3_run-567_stagetwo.model',\n",
        "               'MACE_models/mace02_com2_run-345_stagetwo.model',\n",
        "               'MACE_models/mace02_com1_gen1_run-123_stagetwo.model']\n",
        "\n",
        "xtb_calc = XTB(method=\"GFN2-xTB\")\n",
        "mace_calc = MACECalculator(model_paths=model_paths, device='cpu')\n",
        "\n",
        "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
        "init_conf.calc = mace_calc\n",
        "\n",
        "#initialize the temperature\n",
        "np.random.seed(701)\n",
        "MaxwellBoltzmannDistribution(init_conf, temperature_K=300)\n",
        "Stationary(init_conf)\n",
        "ZeroRotation(init_conf)\n",
        "\n",
        "dyn = Langevin(init_conf, 1*units.fs, temperature_K=1200, friction=0.1)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "time_fs = []\n",
        "temperature = []\n",
        "energies_1 = []\n",
        "energies_2 = []\n",
        "energies_3 = []\n",
        "variances = []\n",
        "xtb_energies = []\n",
        "true_errors = []\n",
        "\n",
        "!rm -rfv moldyn/mace02_md_committee.xyz\n",
        "fig, ax = pl.subplots(4, 1, figsize=(8,8), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "\n",
        "def write_frame():\n",
        "        at = dyn.atoms.copy()\n",
        "        at.calc = xtb_calc\n",
        "        xtb_energy = at.get_potential_energy()\n",
        "\n",
        "        dyn.atoms.write('moldyn/mace02_md_committee.xyz', append=True, write_results=False)\n",
        "        time_fs.append(dyn.get_time()/units.fs)\n",
        "        temperature.append(dyn.atoms.get_temperature())\n",
        "        energies_1.append(dyn.atoms.calc.results[\"energies\"][0]/len(dyn.atoms))\n",
        "        energies_2.append(dyn.atoms.calc.results[\"energies\"][1]/len(dyn.atoms))\n",
        "        energies_3.append(dyn.atoms.calc.results[\"energies\"][2]/len(dyn.atoms))\n",
        "        variances.append(dyn.atoms.calc.results[\"energy_var\"]/len(dyn.atoms))\n",
        "        xtb_energies.append(xtb_energy/len(dyn.atoms))\n",
        "        true_errors.append(np.var([dyn.atoms.calc.results[\"energy\"],xtb_energy])/len(dyn.atoms))\n",
        "\n",
        "        # plot the true error\n",
        "        ax[0].plot(np.array(time_fs), np.array(true_errors), color=\"black\")\n",
        "        ax[0].set_ylabel(r'$\\Delta$ E (eV$^2$/atom)')\n",
        "        ax[0].legend(['Error w.r.t. XTB'], loc='upper left')\n",
        "\n",
        "        # plot committee variance\n",
        "        ax[1].plot(np.array(time_fs), np.array(variances), color=\"y\")\n",
        "        ax[1].set_ylabel(r'committee variance')\n",
        "        ax[1].legend(['Estimated Error (committee variances)'], loc='upper left')\n",
        "\n",
        "        # plot the temperature of the system as subplots\n",
        "        ax[2].plot(np.array(time_fs), temperature, color=\"r\", label='Temperature')\n",
        "        ax[2].set_ylabel(\"T (K)\")\n",
        "\n",
        "        ax[3].plot(np.array(time_fs), energies_1, color=\"g\")\n",
        "        ax[3].plot(np.array(time_fs), energies_2, color=\"y\")\n",
        "        ax[3].plot(np.array(time_fs), energies_3, color=\"olive\")\n",
        "        ax[3].plot(np.array(time_fs), xtb_energies, color=\"black\")\n",
        "        ax[3].set_ylabel(\"E (eV/atom)\")\n",
        "        ax[3].set_xlabel('Time (fs)')\n",
        "        ax[3].legend(['E mace1', 'E mace2', 'E mace3', 'E xtb'], loc='upper left')\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(fig)\n",
        "        time.sleep(0.01)\n",
        "\n",
        "dyn.attach(write_frame, interval=10)\n",
        "dyn.run(500)\n",
        "print(\"MD finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MNDXXavxNVQ"
      },
      "source": [
        "NOTE: if you get the error `xtb could not evalute the config` that means the dynamics went so crazy and gave such strange configurations, that xtb refused to run! thats to be expected if the model is really bad. Copy some of the code above to have a look at the trajectory if you'd like to see this.\n",
        "\n",
        "Closely observe the dynamics. Notice how good the committee error is as a proxy for the true error. In this case the true is cheap to compute, but in most practical applications it won't be. Therefore, we will need to rely on the committee error to identy configurations that should be added back to the training set. This is called active learning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqbEUoAPxNVR"
      },
      "source": [
        "![alt text](https://github.com/imagdau/Tutorials/blob/main/figures/active_learning.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kkq8XlAxNVR"
      },
      "source": [
        "### Active learning in practice\n",
        "\n",
        "The way to use active learning to improve the model is as follows:\n",
        "1. run dynmics, track the uncertainty.\n",
        "2. if the uncertainty breaches some predeterined value, stop the simulation and peform the ground truth calculation.\n",
        "3. and the new config to the dataset, and retrain\n",
        "4. repeat steps 1-3 until the uncertainty never crosses the threshold\n",
        "\n",
        "This can be done without human supervision - you can write a program which loops this process.\n",
        "\n",
        "As an exercise at the end of the notebook, try writing an active learing loop to gradually grow the dataset and produce a good model, without ever running XTB dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9x25o-PxNVR"
      },
      "source": [
        "## 3 Foundational Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoh5bDxqxNVR"
      },
      "source": [
        "### 3.1 Molecular Dynamics with MACE-MP-0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maotXGR3xNVR"
      },
      "source": [
        "Foundation models changed everything. MACE-MP-0 is a model trained on >1 million DFT calcuations, and can run dynamics for the whole periodic table.\n",
        "\n",
        "Mace provides a simple interface to load a foundational model, which we can use mow. Check the [documentation](https://mace-docs.readthedocs.io/en/latest/guide/foundation_models.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySF0cKm1xNVR"
      },
      "outputs": [],
      "source": [
        "from mace.calculators import mace_mp\n",
        "\n",
        "macemp = mace_mp(model=\"mace_agnesi_small.model\", device=\"cuda\")\n",
        "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
        "simpleMD(init_conf, temp=1200, calc=macemp, fname='moldyn/mace03_md.xyz', s=10, T=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRMKjfYBxNVW"
      },
      "source": [
        "OMG, look at that dynamics! Stable out-of-the-box, sign me up! Let's view the trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK9nLfWPxNVW"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "\n",
        "traj = read('moldyn/mace03_md.xyz', ':')\n",
        "view_x3d_n(traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQExiN2xNVW"
      },
      "source": [
        "### 3.2 Compare to XTB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlh6ZyTGxNVW"
      },
      "source": [
        "Let's compute the radial distribution functions of this very stable trajectory and compare them to XTB. Remember MACE-MP was trained on PBE level of theory so we don't necessarily expect them to match:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W2GjUexxNVX"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from aseMolec import anaAtoms as aa\n",
        "\n",
        "tag = 'OO_intra' #choose one of 'HH_intra', 'HC_intra', 'HO_intra', 'CC_intra', 'CO_intra', 'OO_intra'\n",
        "\n",
        "for f in ['xtb_md', 'mace03_md']:\n",
        "    traj = read('moldyn/'+f+'.xyz', '50:') #ignore first 50 frames\n",
        "    for at in traj:\n",
        "        at.pbc = True #create a fake box for rdf compatibility\n",
        "        at.cell = [100,100,100]\n",
        "    rdf = aa.compute_rdfs_traj_avg(traj, rmax=5, nbins=70) #aseMolec provides functionality to compute RDFs\n",
        "    plt.plot(rdf[1], rdf[0][tag], '.-', label=f, alpha=0.7, linewidth=3)\n",
        "\n",
        "plt.legend();\n",
        "plt.yticks([]);\n",
        "plt.xlabel(r'R ($\\rm \\AA$)');\n",
        "plt.ylabel('RDF '+tag);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16UZzmpexNVX"
      },
      "source": [
        "Notice there's a slight shift in the O-O RDF peak. This is likely due to the different level of reference theory. Can we fix by fine tuning MACE-MP-0?\n",
        "\n",
        "Depending on your application, the PBE reference using in MACE-MP-0 may not be appropriate. It is probably better than XTB, but thats because for this notebook we are using XTB since it is extremely fast, so we can check the model's true error very easily.\n",
        "\n",
        "In practice, you might want to run dynamics of this small molecule at the MP2 or coupled cluster level (which is the 'gold standard' of molecular quantum chemistry). In that case, you would want to finetune MACE-MP-0 onto a small amount of very expensive couple cluster data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_kSVlzxxNVX"
      },
      "source": [
        "### 3.3 Fine tune MACE-MP to XTB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF-sDD9ED2yP"
      },
      "source": [
        "As described in the previous section, MACE-MP-0 offers qualitatively good performance across a wide range of chemistries and materials at the PBE+U level of theory.\n",
        "However, for specific applications, it may be beneficial to fine-tune the model to improve its accuracy.\n",
        "The fine-tuning process involves training a pre-trained model on a new dataset, called the fine-tuning dataset, which contains a limited amount of data that are only relevant to the specific application.\n",
        "\n",
        "There exists two ways of finetuning a MACE mode: (1) ***standard*** approach which just restarts training using the parameters of the pretrained model (2) ***multi-head*** approach which ensures that the model does not forget too much about its pretraining.\n",
        "\n",
        "We will start with the ***standard*** aproach below by setting `multiheads_finetuning: False` in the config. When finishing the training, you try to train another model with the ***multi-head*** approach and compare performances in MD. Remember to change the name both in the config and when running MD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mTww8OmD2yP"
      },
      "outputs": [],
      "source": [
        "%%writefile config/config-07.yml\n",
        "\n",
        "model: \"MACE\"\n",
        "stress_weight: 0.0\n",
        "forces_weight: 10.0\n",
        "energy_weight: 1.0\n",
        "foundation_model: \"mace_agnesi_small.model\"\n",
        "multiheads_finetuning: False\n",
        "name: \"finetuned_MACE\"\n",
        "model_dir: \"MACE_models\"\n",
        "log_dir: \"MACE_models\"\n",
        "checkpoints_dir: \"MACE_models\"\n",
        "results_dir: \"MACE_models\"\n",
        "train_file: \"data/solvent_xtb_train_50.xyz\"\n",
        "valid_fraction: 0.10\n",
        "test_file: \"data/solvent_xtb_test.xyz\"\n",
        "energy_key: \"energy_xtb\"\n",
        "forces_key: \"forces_xtb\"\n",
        "device: cuda\n",
        "batch_size: 10\n",
        "max_num_epochs: 500\n",
        "num_samples_pt: 300\n",
        "swa: True\n",
        "seed: 345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc4sneynxNVX"
      },
      "outputs": [],
      "source": [
        "train_mace(\"config/config-07.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT23YJaBD2yP"
      },
      "source": [
        "Compare the final accuracy to the models trained from scratch. You should see that the errors are much better when doing finetuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBaqOL9_xNVX"
      },
      "outputs": [],
      "source": [
        "mace_calc = MACECalculator(model_paths=['MACE_models/finetuned_MACE_run-345_stagetwo.model'], device='cuda')\n",
        "\n",
        "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
        "simpleMD(init_conf, temp=1200, calc=mace_calc, fname='moldyn/mace_finetuned_md.xyz', s=10, T=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61qwBSW3xNVY"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from aseMolec import anaAtoms as aa\n",
        "\n",
        "tag = 'OO_intra' # 'OO_intra' #choose one of 'HH_intra', 'HC_intra', 'HO_intra', 'CC_intra', 'CO_intra', 'OO_intra'\n",
        "\n",
        "for f in ['xtb_md', 'mace_finetuned_md']:\n",
        "    traj = read('moldyn/'+f+'.xyz', '50:') #ignore first 50 frames\n",
        "    for at in traj:\n",
        "        at.pbc = True #create a fake box for rdf compatibility\n",
        "        at.cell = [100,100,100]\n",
        "    rdf = aa.compute_rdfs_traj_avg(traj, rmax=5, nbins=70) #aseMolec provides functionality to compute RDFs\n",
        "    plt.plot(rdf[1], rdf[0][tag], '.-', label=f, alpha=0.7, linewidth=3)\n",
        "\n",
        "plt.legend();\n",
        "plt.yticks([]);\n",
        "plt.xlabel(r'R ($\\rm \\AA$)');\n",
        "plt.ylabel('RDF '+tag);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGjLB6hvxNVY"
      },
      "outputs": [],
      "source": [
        "from ase.io import read, write\n",
        "import nglview as nv\n",
        "\n",
        "traj = read('moldyn/mace_finetuned_md.xyz', ':')\n",
        "view_x3d_n(traj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtaCf0BixNVY"
      },
      "source": [
        "What are the results - does it work?\n",
        "\n",
        "Consider comparing more than one of the rdfs, and looking at how the MP0-model did (as we saw above) vs the finetuned version."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "2a16e1e8a7ad42a8825007f5cff15d19",
    "kernelspec": {
      "display_name": "Python (mace_env)",
      "language": "python",
      "name": "mace_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}